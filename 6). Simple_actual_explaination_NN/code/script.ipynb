{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Package imported\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "print('All Package imported')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#network parameter\n",
    "input_node=4\n",
    "output_node=4\n",
    "layer1=4\n",
    "layer2=4\n",
    "learning_rate=0.3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#placeholders\n",
    "X=tf.placeholder('float',[None,input_node])\n",
    "y=tf.placeholder('float',[None,output_node])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weight and bias\n",
    "\n",
    "weights={\n",
    "    \"w1\":tf.Variable(tf.random_normal([input_node,layer1])),\n",
    "    \"w2\":tf.Variable(tf.random_normal([layer1,layer2])),\n",
    "    \"w_out\":tf.Variable(tf.random_normal([layer2,output_node]))\n",
    "}\n",
    "bias={\n",
    "    \"b1\":tf.Variable(tf.random_normal([layer1])),\n",
    "    \"b2\":tf.Variable(tf.random_normal([layer2])),\n",
    "    \"b_out\":tf.Variable(tf.random_normal([output_node]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(input_data,weights,bias):\n",
    "    layer1=tf.add(tf.matmul(input_data,weights['w1']),bias['b1'])\n",
    "    layer2=tf.add(tf.matmul(layer1,weights['w2']),bias['b2'])\n",
    "    output=tf.add(tf.matmul(layer2,weights['w_out']),bias['b_out'])\n",
    "    return output\n",
    "\n",
    "logits=model(X,weights,bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['solid', 'solid', 'horizontal', 'horizontal', 'vertical', 'vertical', 'diognal', 'diognal']\n",
      "[[1, 1, 1, 1], [0, 0, 0, 0], [1, 1, 0, 0], [0, 0, 1, 1], [0, 1, 0, 1], [1, 0, 1, 0], [1, 0, 0, 1], [0, 1, 1, 0]]\n"
     ]
    }
   ],
   "source": [
    "source=[[[1,1],[1,1]],[[0,0],[0,0]],[[1,1],[0,0]],[[0,0],[1,1]],[[0,1],[0,1]],[[1,0],[1,0]],[[1,0],[0,1]],[[0,1],[1,0]]]\n",
    "source=np.reshape(source,[-1,4])\n",
    "target=[\"solid\",\"solid\",\"horizontal\",\"horizontal\",\"vertical\",\"vertical\",\"diognal\",\"diognal\"]\n",
    "print(target)\n",
    "print(source.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0]]\n"
     ]
    }
   ],
   "source": [
    "#prepare data to get feeded\n",
    "def map_unique_value(input):\n",
    "    unique_key_values={each:index for index,each in enumerate(set(input))}\n",
    "    output=[unique_key_values[each] for each in input]\n",
    "    return output\n",
    "def indices_to_one_hot(data, nb_classes):\n",
    "    \"\"\"Convert an iterable of indices to one-hot encoded labels.\"\"\"\n",
    "    targets = np.array(data).reshape(-1)\n",
    "    return np.eye(nb_classes)[targets]\n",
    "    \n",
    "\n",
    "labels=indices_to_one_hot(map_unique_value(target),4).tolist()\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits,labels=labels))\n",
    "optimizer=tf.train.AdamOptimizer(learning_rate=learning_rate);\n",
    "opt=optimizer.minimize(train_loss)\n",
    "\n",
    "\n",
    "corre_pred=tf.equal(tf.argmax(logits,1),tf.argmax(labels,1))\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(corre_pred, tf.float32))\n",
    "\n",
    "init=tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_batch(num, data, labels):\n",
    "    '''\n",
    "    Return a total of `num` random samples and labels. \n",
    "    '''\n",
    "    idx = np.arange(0 , len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = [data[ i] for i in idx]\n",
    "    labels_shuffle = [labels[ i] for i in idx]\n",
    "\n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy :  [0.5]\n",
      "accuracy :  [0.375]\n",
      "accuracy :  [0.125]\n",
      "accuracy :  [0.25]\n",
      "accuracy :  [0.0]\n",
      "accuracy :  [0.375]\n",
      "accuracy :  [0.375]\n",
      "accuracy :  [0.25]\n",
      "accuracy :  [0.25]\n",
      "accuracy :  [0.125]\n",
      "accuracy :  [0.375]\n",
      "accuracy :  [0.25]\n",
      "accuracy :  [0.25]\n",
      "accuracy :  [0.375]\n",
      "accuracy :  [0.375]\n",
      "accuracy :  [0.0]\n",
      "accuracy :  [0.375]\n",
      "accuracy :  [0.125]\n",
      "accuracy :  [0.125]\n",
      "accuracy :  [0.125]\n",
      "accuracy :  [0.375]\n",
      "accuracy :  [0.375]\n",
      "accuracy :  [0.25]\n",
      "accuracy :  [0.375]\n",
      "accuracy :  [0.375]\n",
      "accuracy :  [0.375]\n",
      "accuracy :  [0.375]\n",
      "accuracy :  [0.125]\n",
      "accuracy :  [0.125]\n",
      "accuracy :  [0.25]\n",
      "accuracy :  [0.375]\n",
      "accuracy :  [0.125]\n",
      "accuracy :  [0.25]\n",
      "accuracy :  [0.125]\n",
      "accuracy :  [0.375]\n",
      "accuracy :  [0.25]\n",
      "accuracy :  [0.25]\n",
      "accuracy :  [0.125]\n",
      "accuracy :  [0.25]\n",
      "accuracy :  [0.5]\n",
      "accuracy :  [0.5]\n",
      "accuracy :  [0.25]\n",
      "accuracy :  [0.25]\n",
      "accuracy :  [0.125]\n",
      "accuracy :  [0.125]\n",
      "accuracy :  [0.25]\n",
      "accuracy :  [0.375]\n",
      "accuracy :  [0.125]\n",
      "accuracy :  [0.25]\n",
      "accuracy :  [0.125]\n",
      "accuracy :  [0.125]\n",
      "accuracy :  [0.25]\n",
      "accuracy :  [0.375]\n",
      "accuracy :  [0.5]\n",
      "accuracy :  [0.25]\n",
      "accuracy :  [0.25]\n",
      "accuracy :  [0.5]\n",
      "accuracy :  [0.0]\n",
      "accuracy :  [0.125]\n",
      "accuracy :  [0.375]\n",
      "accuracy :  [0.125]\n",
      "accuracy :  [0.0]\n",
      "accuracy :  [0.375]\n",
      "accuracy :  [0.25]\n",
      "accuracy :  [0.375]\n",
      "accuracy :  [0.25]\n",
      "accuracy :  [0.25]\n",
      "accuracy :  [0.375]\n",
      "accuracy :  [0.375]\n",
      "accuracy :  [0.125]\n",
      "accuracy :  [0.375]\n",
      "accuracy :  [0.125]\n",
      "accuracy :  [0.25]\n",
      "accuracy :  [0.375]\n",
      "accuracy :  [0.25]\n",
      "accuracy :  [0.125]\n",
      "accuracy :  [0.25]\n",
      "accuracy :  [0.125]\n",
      "accuracy :  [0.375]\n",
      "accuracy :  [0.25]\n",
      "accuracy :  [0.25]\n",
      "accuracy :  [0.125]\n",
      "accuracy :  [0.125]\n",
      "accuracy :  [0.25]\n",
      "accuracy :  [0.25]\n",
      "accuracy :  [0.25]\n",
      "accuracy :  [0.125]\n",
      "accuracy :  [0.25]\n",
      "accuracy :  [0.5]\n",
      "accuracy :  [0.25]\n",
      "accuracy :  [0.375]\n",
      "accuracy :  [0.125]\n",
      "accuracy :  [0.375]\n",
      "accuracy :  [0.375]\n",
      "accuracy :  [0.25]\n",
      "accuracy :  [0.25]\n",
      "accuracy :  [0.375]\n",
      "accuracy :  [0.375]\n",
      "accuracy :  [0.25]\n",
      "accuracy :  [0.125]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for  i in range(100):\n",
    "        source,labels=next_batch(8,source,labels)\n",
    "    \n",
    "        out=sess.run([accuracy],feed_dict={X:source,y:labels})\n",
    "        print('accuracy : ',out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
